{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a98f227",
   "metadata": {},
   "source": [
    "#### Data Analysis, Cleansing, and Normalization\n",
    "\n",
    "This notebook guides you through analyzing, cleansing, and normalizing a dataset using Python.\n",
    "\n",
    "- Analyze the dataset.\n",
    "- Cleanse missing or incorrect data.\n",
    "- Normalize data into a consistent format.\n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91d5b22",
   "metadata": {},
   "source": [
    "#### Step 1: Data Analysis\n",
    "\n",
    "In this step, we will load the dataset and perform some basic analysis to understand its structure and contents.\n",
    "\n",
    "1. Load the dataset.\n",
    "2. Display the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcae2bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('/drive/datasets/climatebert-netzero-reduction-data.csv')\n",
    "\n",
    "#display the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564943f5",
   "metadata": {},
   "source": [
    "#### Step 2: Data Cleansing\n",
    "\n",
    "Data cleansing involves identifying and correcting or removing incorrect, incomplete, or irrelevant data. In this step, we'll:\n",
    "1. Check for missing values.\n",
    "2. Remove rows with missing values in the 'text' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacaf5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values)\n",
    "\n",
    "# Remove rows with missing values in the 'text' column\n",
    "data_cleaned = data.dropna(subset=['text'])\n",
    "\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2736e6f3",
   "metadata": {},
   "source": [
    "#### Step 3: Data Normalization\n",
    "\n",
    "Data normalization involves transforming data into a consistent format.\n",
    "1. Convert all text in the 'text' column to lowercase.\n",
    "2. Remove special characters and numbers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae6b08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Convert all text to lowercase\n",
    "data_cleaned['text'] = data_cleaned['text'].str.lower()\n",
    "\n",
    "# Remove special characters and numbers\n",
    "data_cleaned['text'] = data_cleaned['text'].apply(lambda x: re.sub(r'[^a-z\\s]', '', x))\n",
    "\n",
    "data_cleaned.head() # Display the normalized dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f582aa66",
   "metadata": {},
   "source": [
    "#### Step 4: Counting Occurrences\n",
    "\n",
    "Now that we have cleaned and normalized the data, let's count the occurrences of the terms 'percent' and 'carbon dioxide' in the 'text' column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff6f08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of 'percent' and 'carbon dioxide' in 'text' column\n",
    "count_percent = data_cleaned['text'].str.contains('percent').sum()\n",
    "count_carbon_dioxide = data_cleaned['text'].str.contains('carbon dioxide').sum()\n",
    "\n",
    "# Display the results\n",
    "print(f\"Occurrences of 'percent': {count_percent}\")\n",
    "print(f\"Occurrences of 'carbon dioxide': {count_carbon_dioxide}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c4cd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Replace occurrences of 'percent' with '%' and 'carbon dioxide' with 'CO2'\n",
    "data_cleaned['text'] = data_cleaned['text'].str.replace('percent', '%')\n",
    "data_cleaned['text'] = data_cleaned['text'].str.replace('carbon dioxide', 'CO2')\n",
    "\n",
    "# Display the updated dataset\n",
    "data_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829406b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Recount occurrences after replacement\n",
    "count_percent_replaced = data_cleaned['text'].str.contains('%').sum()\n",
    "count_co2_replaced = data_cleaned['text'].str.contains('CO2').sum()\n",
    "\n",
    "# Display the results\n",
    "print(f\"Occurrences of '%': {count_percent_replaced}\")\n",
    "print(f\"Occurrences of 'CO2': {count_co2_replaced}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81f377e",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "In this notebook, we learned how to:\n",
    "1. Analyze a dataset to understand its structure.\n",
    "2. Cleanse the data by handling missing values.\n",
    "3. Normalize the data for consistency.\n",
    "4. Count specific term occurrences\n",
    "\n",
    "These are all typical steps in data processing for preparing data for further analysis or machine learning.\n",
    "\n",
    "Great job!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
