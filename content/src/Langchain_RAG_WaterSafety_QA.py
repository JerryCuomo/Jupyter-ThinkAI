# Source: "Think Artificial Intelligence" by Jerry Cuomo, 2024
# Purpose: Demonstrates LangChain agents' capability to autonomously navigate through a sequence of tools for data retrieval, calculation, and summarization, highlighting their role in AI-driven data analysis.
# Copyright Â© 2024 Jerry Cuomo. All rights reserved.
#
# This code was autogenerated by GPT-4 in response to a complex task requiring the integration of multiple AI and database technologies to process and analyze data:
# Prompt: Prompt: Utilize LangChain to demonstrate the RAG technique. The script should load a given {.txt file}, segment it into chunks, vectorize these segments in ChromaDB, and formulate an answer to a {human-provided question} with {language} to respond in and {guidance to respond in plain English}."
# About: While the example provided focuses on consumer safety related to safe water standards, the script itself is designed to be versatile, capable of processing any text dataset to autonomously find, analyze, and summarize information on a wide range of topics as requested by the user, ensuring the response is accessible and in the specified language.
# Setup: Python environment with LangChain-Community and ChromaDB installed is required. The OPENAI_API_KEY must be securely stored for the script to access OpenAI's services.
# Note: The example demonstrates the process of chunking a large text dataset, embedding it for efficient retrieval, querying relevant information, and then summarizing the findings in a concise manner.
# Install necessary packages for running the script
# pip install chromadb 
# pip install -U langchain-community
#
from langchain_openai import ChatOpenAI
from langchain_openai import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.vectorstores import Chroma
import os

# Set the OpenAI API key in the environment securely
os.environ["OPENAI_API_KEY"] = "INSERT_OPENAI_API_KEY_HERE"

# Prepare the dataset by splitting it into manageable chunks for processing
full_text = open("../datasets/EPA-consumer-safety-safe-water.txt", "r").read()
text_splitter = CharacterTextSplitter(chunk_size=2048, chunk_overlap=100)
texts = text_splitter.split_text(full_text)

# Initialize the embedding model and create a searchable database from the chunked texts
embeddings = OpenAIEmbeddings()
db = Chroma.from_texts(texts, embeddings)
retriever = db.as_retriever()

# Use the retriever to find documents relevant to the query about safe drinking water
retrieved_docs = retriever.invoke("What is considered safe drinking water?")

# Configure the prompt template for concise summarization
prompt = ChatPromptTemplate.from_messages([
    ("system", "Please summarize the response in {language} in 30 words or less. {validate}"),
    ("human", "{input}")
])

# Set up the LangChain LLM for processing the information retrieved, defining the sequence for action
llm = ChatOpenAI(temperature=0)
chain = prompt | llm

# Execute the chain on the first retrieved document, specifying the output language and summary style
response = chain.invoke({"input": retrieved_docs[0].page_content, "language": "Spanish", "validate": "Ensure clarity and accessibility"})
print(response)
